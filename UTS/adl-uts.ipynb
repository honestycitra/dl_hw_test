{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Reproduce P1.XNet - UTS**","metadata":{}},{"cell_type":"markdown","source":"Paper: https://paperswithcode.com/paper/xnet-a-convolutional-neural-network-cnn\n\nXNet Model: https://github.com/JosephPB/XNet\n\nDataset: https://www.kaggle.com/nikhilpandey360/chest-xray-masks-and-labels\n\nNotebook: https://www.kaggle.com/code/pezhmansamadi/resu-net-retrain/notebook","metadata":{}},{"cell_type":"code","source":"!pip install -q mlflow","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:33.184162Z","iopub.execute_input":"2022-04-10T14:46:33.184455Z","iopub.status.idle":"2022-04-10T14:46:41.880141Z","shell.execute_reply.started":"2022-04-10T14:46:33.184427Z","shell.execute_reply":"2022-04-10T14:46:41.879026Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Modul","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:41.884132Z","iopub.execute_input":"2022-04-10T14:46:41.884408Z","iopub.status.idle":"2022-04-10T14:46:41.898952Z","shell.execute_reply.started":"2022-04-10T14:46:41.884377Z","shell.execute_reply":"2022-04-10T14:46:41.897767Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# Dataset\n### Montgomery and Shenzhen for train\nhttps://www.kaggle.com/nikhilpandey360/chest-xray-masks-and-labels","metadata":{}},{"cell_type":"code","source":"image_path_train = '../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png/'\nmask_path_train = '../input/chest-xray-masks-and-labels/Lung Segmentation/masks/'\nimage_path_test = '../input/chest-xray-masks-and-labels/Lung Segmentation/test/' ","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:41.900816Z","iopub.execute_input":"2022-04-10T14:46:41.901610Z","iopub.status.idle":"2022-04-10T14:46:41.907884Z","shell.execute_reply.started":"2022-04-10T14:46:41.901554Z","shell.execute_reply":"2022-04-10T14:46:41.906240Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"images = os.listdir(image_path_train)\nmask = os.listdir(mask_path_train)\nmask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:41.911627Z","iopub.execute_input":"2022-04-10T14:46:41.912430Z","iopub.status.idle":"2022-04-10T14:46:41.931078Z","shell.execute_reply.started":"2022-04-10T14:46:41.912398Z","shell.execute_reply":"2022-04-10T14:46:41.929967Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\", len(check))\ntesting_files = set(os.listdir(image_path_train)) & set(os.listdir(mask_path_train))\ntraining_files = check","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:41.933847Z","iopub.execute_input":"2022-04-10T14:46:41.934677Z","iopub.status.idle":"2022-04-10T14:46:41.944551Z","shell.execute_reply.started":"2022-04-10T14:46:41.934636Z","shell.execute_reply":"2022-04-10T14:46:41.943239Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Dataset","metadata":{}},{"cell_type":"code","source":"def getData(X_shape, flag = \"test\"):\n    im_array = []\n    mask_array = []\n    shape = (X_shape, X_shape)\n    # X_shape = image_size\n    if flag == \"test\":\n        for i in tqdm(testing_files): \n            \n            # im.shape = (X_shape, X_shape, 1)\n            im = cv2.imread(os.path.join(image_path_train, i), cv2.IMREAD_GRAYSCALE)\n            im = cv2.resize(im, shape)\n            im = cv2.equalizeHist(im)\n            # mask.shape = (X_shape, X_shape, 1)\n            mask = cv2.imread(os.path.join(mask_path_train, i), cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, shape)\n            \n            im_array.append(im)\n            mask_array.append(mask)\n    \n    if flag == \"train\":\n        for i in tqdm(training_files): \n            \n            # im.shape = (X_shape, X_shape, 1)\n            im = cv2.imread(os.path.join(image_path_train, i.split(\"_mask\")[0] + \".png\"), cv2.IMREAD_GRAYSCALE)\n            im = cv2.resize(im, shape)\n            im = cv2.equalizeHist(im)\n            # mask.shape = (X_shape, X_shape, 1)\n            mask = cv2.imread(os.path.join(mask_path_train, i + \".png\"), cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, shape)\n            \n            im_array.append(im)\n            mask_array.append(mask)\n    # return list\n    return im_array, mask_array","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:41.946978Z","iopub.execute_input":"2022-04-10T14:46:41.947824Z","iopub.status.idle":"2022-04-10T14:46:41.960919Z","shell.execute_reply.started":"2022-04-10T14:46:41.947783Z","shell.execute_reply":"2022-04-10T14:46:41.959850Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def get_test(X_shape, n_samples = 100):\n    im_array = []\n    shape = (X_shape, X_shape)\n    test_files = random.choices(list(os.listdir(image_path_test)), k=n_samples)\n    for i in tqdm(test_files):\n        im = cv2.imread(os.path.join(image_path_test, i), cv2.IMREAD_GRAYSCALE)\n        im = cv2.resize(im, shape)\n        im = cv2.equalizeHist(im)\n        im_array.append(im)\n    return im_array","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:41.964878Z","iopub.execute_input":"2022-04-10T14:46:41.965708Z","iopub.status.idle":"2022-04-10T14:46:41.974467Z","shell.execute_reply.started":"2022-04-10T14:46:41.965650Z","shell.execute_reply":"2022-04-10T14:46:41.972948Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"# Loading images and masks","metadata":{}},{"cell_type":"code","source":"dim, n_samples = 256, 50 # n_samples = [1, 96]\n\nimage_train, mask_train = getData(dim, flag = \"train\")\nimage_test, mask_test = getData(dim, flag = \"test\")\nX_test = get_test(dim, n_samples = n_samples)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:46:41.976347Z","iopub.execute_input":"2022-04-10T14:46:41.976766Z","iopub.status.idle":"2022-04-10T14:48:52.891277Z","shell.execute_reply.started":"2022-04-10T14:46:41.976725Z","shell.execute_reply":"2022-04-10T14:48:52.890182Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"image_train = np.array(image_train).reshape(len(image_train), dim, dim, 1)\nmask_train = np.array(mask_train).reshape(len(mask_train), dim, dim, 1)\n\nimage_test = np.array(image_test).reshape(len(image_test), dim, dim, 1)\nmask_test = np.array(mask_test).reshape(len(mask_test), dim, dim, 1)\n\nX_test = np.array(X_test).reshape(len(X_test), dim, dim, 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:52.893087Z","iopub.execute_input":"2022-04-10T14:48:52.893797Z","iopub.status.idle":"2022-04-10T14:48:52.934579Z","shell.execute_reply.started":"2022-04-10T14:48:52.893752Z","shell.execute_reply":"2022-04-10T14:48:52.933404Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"print(image_train.shape, mask_train.shape)\nprint(image_test.shape, mask_test.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:52.939527Z","iopub.execute_input":"2022-04-10T14:48:52.939775Z","iopub.status.idle":"2022-04-10T14:48:52.947566Z","shell.execute_reply.started":"2022-04-10T14:48:52.939748Z","shell.execute_reply":"2022-04-10T14:48:52.946202Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"i = 25\nfig, axs = plt.subplots(nrows=3, ncols=2, figsize=(9, 13))\naxs[0, 0].imshow(image_train[i], cmap='gray')\naxs[0, 1].imshow(mask_train[i], cmap='gray')\naxs[0, 0].set_ylabel('Shenzhen')\n\naxs[1, 0].imshow(image_test[i], cmap='gray')\naxs[1, 1].imshow(mask_test[i], cmap='gray')\naxs[1, 0].set_ylabel('Montgomery')\n\naxs[2, 0].imshow(X_test[i], cmap='gray')\naxs[2, 0].set_ylabel('NIH')\n\naxs[0, 0].set_title('CXR')\naxs[1, 0].set_title('CXR')\naxs[2, 0].set_title('CXR')\n\naxs[0, 1].set_title('mask')\naxs[1, 1].set_title('mask')\n\nfig.delaxes(axs[2, 1])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:52.949782Z","iopub.execute_input":"2022-04-10T14:48:52.950747Z","iopub.status.idle":"2022-04-10T14:48:54.119749Z","shell.execute_reply.started":"2022-04-10T14:48:52.950702Z","shell.execute_reply":"2022-04-10T14:48:54.118824Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"assert image_train.shape == mask_train.shape\nassert image_test.shape == mask_test.shape\nimages = np.concatenate((image_train, image_test), axis=0)\nmasks  = np.concatenate((mask_train, mask_test), axis=0)\n\nprint(images.shape, masks.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.121279Z","iopub.execute_input":"2022-04-10T14:48:54.122329Z","iopub.status.idle":"2022-04-10T14:48:54.161835Z","shell.execute_reply.started":"2022-04-10T14:48:54.122261Z","shell.execute_reply":"2022-04-10T14:48:54.160710Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmetation\ncreate_contrast_images_v1","metadata":{}},{"cell_type":"code","source":"def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n    \n    if brightness != 0:\n        if brightness > 0:\n            shadow = brightness\n            highlight = 255\n        else:\n            shadow = 0\n            highlight = 255 + brightness\n        alpha_b = (highlight - shadow) / 255.0\n        gamma_b = shadow\n        \n        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n    else:\n        buf = input_img.copy()\n    \n    if contrast != 0:\n        f = 131 * (contrast + 127) / (127 * (131 - contrast))\n        alpha_c = f\n        gamma_c = 127 * (1 - f)\n        \n        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n\n    return buf","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:00:42.165699Z","iopub.execute_input":"2022-04-10T15:00:42.165991Z","iopub.status.idle":"2022-04-10T15:00:42.177565Z","shell.execute_reply.started":"2022-04-10T15:00:42.165962Z","shell.execute_reply":"2022-04-10T15:00:42.176448Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def create_contrast_images_v1(b, c):\n    contrast_images = []\n    for i in tqdm(range(len(images)), \"contrast_images\"):\n        contrast_images.append(apply_brightness_contrast(images[i], brightness=b, contrast=c))\n    return contrast_images","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:00:53.719657Z","iopub.execute_input":"2022-04-10T15:00:53.720002Z","iopub.status.idle":"2022-04-10T15:00:53.725775Z","shell.execute_reply.started":"2022-04-10T15:00:53.719973Z","shell.execute_reply":"2022-04-10T15:00:53.724676Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"b, c = -40, -120\n\ncontrast_images_v1 = create_contrast_images_v1(b, c)\ncontrast_images_v1 = np.array(contrast_images_v1).reshape(len(contrast_images_v1), 256, 256, 1)\nprint(f'\\nshape = {contrast_images_v1.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:01:03.632951Z","iopub.execute_input":"2022-04-10T15:01:03.634020Z","iopub.status.idle":"2022-04-10T15:01:03.717165Z","shell.execute_reply.started":"2022-04-10T15:01:03.633978Z","shell.execute_reply":"2022-04-10T15:01:03.716219Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"**create_contrast_images_v2**","metadata":{}},{"cell_type":"code","source":"def create_contrast_images_v2(alpha, beta):\n    contrast_images_v2 = []\n    for i in tqdm(range(len(images)), \"contrast_images\"):\n        contrast_images_v2.append(cv2.addWeighted(images[i], alpha, images[i], 0, beta))\n    return contrast_images_v2","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:01:41.344147Z","iopub.execute_input":"2022-04-10T15:01:41.344437Z","iopub.status.idle":"2022-04-10T15:01:41.353548Z","shell.execute_reply.started":"2022-04-10T15:01:41.344409Z","shell.execute_reply":"2022-04-10T15:01:41.352339Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"alpha = 1.5 #@alpha\nbeta = 0.7 #@beta\n\ncontrast_images_v2 = create_contrast_images_v2(alpha, beta)\ncontrast_images_v2 = np.array(contrast_images_v2).reshape(len(contrast_images_v2), 256, 256, 1)\nprint(f'\\nshape = {contrast_images_v2.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:01:49.944598Z","iopub.execute_input":"2022-04-10T15:01:49.945246Z","iopub.status.idle":"2022-04-10T15:01:50.001965Z","shell.execute_reply.started":"2022-04-10T15:01:49.945187Z","shell.execute_reply":"2022-04-10T15:01:50.000723Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"**create_noise_images**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train= train_test_split((X - 127.0) / 127.0,(y > 127).astype(np.float32),test_size = 0.15,random_state = 0)\nX_val= train_test_split((X - 127.0) / 127.0,(y > 127).astype(np.float32),test_size = 0.15,random_state = 0)\nY_train= train_test_split((X - 127.0) / 127.0,(y > 127).astype(np.float32),test_size = 0.15,random_state = 0)\nY_val= train_test_split((X - 127.0) / 127.0,(y > 127).astype(np.float32),test_size = 0.15,random_state = 0)\nX_testNorm = (X_test - 127.0) / 127.0","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:58:01.513110Z","iopub.execute_input":"2022-04-10T14:58:01.513465Z","iopub.status.idle":"2022-04-10T14:58:01.544817Z","shell.execute_reply.started":"2022-04-10T14:58:01.513436Z","shell.execute_reply":"2022-04-10T14:58:01.543267Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport mlflow\nimport mlflow.tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.195887Z","iopub.status.idle":"2022-04-10T14:48:54.196576Z","shell.execute_reply.started":"2022-04-10T14:48:54.196177Z","shell.execute_reply":"2022-04-10T14:48:54.196220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef jaccard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\ndef jaccard_coef_loss(y_true, y_pred):\n    return 1 - jaccard_coef(y_true, y_pred) ","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.199351Z","iopub.status.idle":"2022-04-10T14:48:54.199986Z","shell.execute_reply.started":"2022-04-10T14:48:54.199663Z","shell.execute_reply":"2022-04-10T14:48:54.199692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def XNet(input_shape=(256,256,1), classes=1, kernel_size = 3, filter_depth = (16,32,64,128,0)):\n    img_input = Input(input_shape)\n    \n    # Encoder\n    conv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(img_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = Activation(\"relu\")(batch1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n    #100x100\n    \n    conv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(pool1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = Activation(\"relu\")(batch2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n    #50x50\n    \n    conv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = Activation(\"relu\")(batch3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n    #25x25\n    \n    #Flat\n    conv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = Activation(\"relu\")(batch4)\n    #25x25\n    \n    conv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = Activation(\"relu\")(batch5)\n    #25x25\n    \n    #Up\n    up6 = UpSampling2D(size=(2, 2))(act5)\n    conv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up6)\n    batch6 = BatchNormalization()(conv6)\n    act6 = Activation(\"relu\")(batch6)\n    concat6 = Concatenate()([act3,act6])\n    #50x50\n    \n    up7 = UpSampling2D(size=(2, 2))(concat6)\n    conv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up7)\n    batch7 = BatchNormalization()(conv7)\n    act7 = Activation(\"relu\")(batch7)\n    concat7 = Concatenate()([act2,act7])\n    #100x100\n    \n    #Down\n    conv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = Activation(\"relu\")(batch8)\n    pool8 = MaxPooling2D(pool_size=(2, 2))(act8)\n    #50x50\n    \n    conv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = Activation(\"relu\")(batch9)\n    pool9 = MaxPooling2D(pool_size=(2, 2))(act9)\n    \n    #25x25\n    \n    #Flat\n    conv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = Activation(\"relu\")(batch10)\n    #25x25\n    \n    conv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = Activation(\"relu\")(batch11)\n    #25x25\n    \n    #Encoder\n    up12 = UpSampling2D(size=(2, 2))(act11)\n    conv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up12)\n    batch12 = BatchNormalization()(conv12)\n    act12 = Activation(\"relu\")(batch12)\n    concat12 = Concatenate()([act9,act12])\n    #50x50\n    \n    up13 = UpSampling2D(size=(2, 2))(concat12)\n    conv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up13)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  Activation(\"relu\")(batch13)\n    concat13 = Concatenate()([act8,act13])\n    #100x100\n    \n    up14 = UpSampling2D(size=(2, 2))(concat13)\n    conv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(up14)\n    batch14 = BatchNormalization()(conv14)\n    act14 = Activation(\"relu\")(batch14)\n    concat14 = Concatenate()([act1,act14])\n    #200x200\n    \n    conv15 = Conv2D(1, (1, 1), activation='sigmoid')(concat14)\n\n    return Model(inputs=[img_input], outputs=[conv15])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.202430Z","iopub.status.idle":"2022-04-10T14:48:54.203146Z","shell.execute_reply.started":"2022-04-10T14:48:54.202721Z","shell.execute_reply":"2022-04-10T14:48:54.202751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XNet(input_shape=(dim, dim, 1))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.205565Z","iopub.status.idle":"2022-04-10T14:48:54.206219Z","shell.execute_reply.started":"2022-04-10T14:48:54.205886Z","shell.execute_reply":"2022-04-10T14:48:54.205930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                                   patience=4, \n                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=35) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.208536Z","iopub.status.idle":"2022-04-10T14:48:54.209382Z","shell.execute_reply.started":"2022-04-10T14:48:54.209029Z","shell.execute_reply":"2022-04-10T14:48:54.209059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = [dice_coef, jaccard_coef,\n           'binary_accuracy', \n           tf.keras.metrics.Precision(), \n           tf.keras.metrics.Recall()]\n\nloss = [dice_coef_loss, \n        jaccard_coef_loss,\n        'binary_crossentropy']","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.210873Z","iopub.status.idle":"2022-04-10T14:48:54.211694Z","shell.execute_reply.started":"2022-04-10T14:48:54.211363Z","shell.execute_reply":"2022-04-10T14:48:54.211392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = Adam(lr = 1e-4), \n              loss = loss, \n              metrics = metrics)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.213248Z","iopub.status.idle":"2022-04-10T14:48:54.214035Z","shell.execute_reply.started":"2022-04-10T14:48:54.213705Z","shell.execute_reply":"2022-04-10T14:48:54.213732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model","metadata":{}},{"cell_type":"code","source":"res = model.fit(X_train, Y_train, \n                validation_data=(X_val, Y_val), \n                batch_size=32, epochs=100,\n                callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.215495Z","iopub.status.idle":"2022-04-10T14:48:54.216385Z","shell.execute_reply.started":"2022-04-10T14:48:54.216059Z","shell.execute_reply":"2022-04-10T14:48:54.216086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(res.history['loss'], '-', label = 'Loss')\nax1.plot(res.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100 * np.array(res.history['binary_accuracy']), '-', \n         label = 'Accuracy')\nax2.plot(100 * np.array(res.history['val_binary_accuracy']), '-',\n         label = 'Validation Accuracy')\nax2.legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.217934Z","iopub.status.idle":"2022-04-10T14:48:54.218738Z","shell.execute_reply.started":"2022-04-10T14:48:54.218449Z","shell.execute_reply":"2022-04-10T14:48:54.218474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediksi dari Validasiset","metadata":{}},{"cell_type":"code","source":"preds_val = model.predict(X_val)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.220326Z","iopub.status.idle":"2022-04-10T14:48:54.221168Z","shell.execute_reply.started":"2022-04-10T14:48:54.220860Z","shell.execute_reply":"2022-04-10T14:48:54.220888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=5, ncols=3, figsize=(10, 20))\n\nfor i in range(5):\n    for j in range(3):\n        if j == 0:\n            axs[i, j].imshow(X_val[i + 10], cmap='gray')\n            axs[i, j].set_title('CXR')\n        elif j == 1:\n            axs[i, j].imshow(preds_val[i + 10], cmap='gray')\n            axs[i, j].set_title('predicted mask')\n       \n        elif j == 2:\n            axs[i, j].imshow(Y_val[i + 10], cmap='gray')\n            axs[i, j].set_title('Actual mask')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.222745Z","iopub.status.idle":"2022-04-10T14:48:54.223565Z","shell.execute_reply.started":"2022-04-10T14:48:54.223235Z","shell.execute_reply":"2022-04-10T14:48:54.223277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction dari testset","metadata":{}},{"cell_type":"code","source":"preds = model.predict(X_testNorm)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.225316Z","iopub.status.idle":"2022-04-10T14:48:54.226331Z","shell.execute_reply.started":"2022-04-10T14:48:54.225920Z","shell.execute_reply":"2022-04-10T14:48:54.225951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(10, 20))\n\nfor i in range(5):\n    for j in range(2):\n        if j != 1:\n            axs[i, j].imshow(X_testNorm[i + 10], cmap='gray')\n            axs[i, j].set_title('CXR')\n        else:\n            axs[i, j].imshow(preds[i + 10], cmap='gray')\n            axs[i, j].set_title('predicted mask')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:48:54.227878Z","iopub.status.idle":"2022-04-10T14:48:54.228677Z","shell.execute_reply.started":"2022-04-10T14:48:54.228365Z","shell.execute_reply":"2022-04-10T14:48:54.228392Z"},"trusted":true},"execution_count":null,"outputs":[]}]}