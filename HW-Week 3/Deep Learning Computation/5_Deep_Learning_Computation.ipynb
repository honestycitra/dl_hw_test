{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. Deep Learning Computation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Computation"
      ],
      "metadata": {
        "id": "HjzUUYRsPeY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada chapter 5 ini, akan dibahas mengenai komponen kunci komputasi dalam deep learning, yaitu kontruksi model, akses parameter, dan inisialisasi, merancang layers dan blocks khusus, membaca dan menulis model ke disk, dan memanfaatkan GPU untuk mencapai hasil dengan percepatan yang dramatik."
      ],
      "metadata": {
        "id": "SyI82MFCOwaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l\n",
        "!pip install matplotlib==3.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GiampKLYQTdj",
        "outputId": "c5d9049c-750f-49d3-cfca-ad9dfe1568dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l in /usr/local/lib/python3.7/dist-packages (0.17.5)\n",
            "Collecting matplotlib==3.5.1\n",
            "  Using cached matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Requirement already satisfied: pandas==1.2.4 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.2.4)\n",
            "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.7/dist-packages (from d2l) (2.25.1)\n",
            "Requirement already satisfied: numpy==1.21.5 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.21.5)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.7.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (4.32.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (3.0.8)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (1.4.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4->d2l) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2021.10.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.5.1->d2l) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1->d2l) (1.15.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.1.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (5.3.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.9.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (5.6.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.11.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.0.1)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.0.2\n",
            "    Uninstalling matplotlib-3.0.2:\n",
            "      Successfully uninstalled matplotlib-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib==3.0.2\n",
            "  Using cached matplotlib-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (12.9 MB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.0.2) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.5.1\n",
            "    Uninstalling matplotlib-3.5.1:\n",
            "      Successfully uninstalled matplotlib-3.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.2 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.2 which is incompatible.\n",
            "d2l 0.17.5 requires matplotlib==3.5.1, but you have matplotlib 3.0.2 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Layers dan Blocks**"
      ],
      "metadata": {
        "id": "qZ6EZwSSPW-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode berikut ini menghasilkan network dengan satu layer tersembunyi yang tehubung penuh dengan 256 unit dan aktivasi ReLU, yang dibarengi oleh output layer yang terhubung penuh dengan 10 unit (tanpa fungsi aktivasi)"
      ],
      "metadata": {
        "id": "jBww331NPnAX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9frjElnN7EW",
        "outputId": "e1e1f71d-13f8-44c9-d334-a8e9ffb193ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3271,  0.2411, -0.0707,  0.0556,  0.0018, -0.1940, -0.2239, -0.2439,\n",
              "          0.0358,  0.1026],\n",
              "        [ 0.1533,  0.0781, -0.1266,  0.0252,  0.0458, -0.2297, -0.2295, -0.1013,\n",
              "         -0.0545,  0.1378]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l\n",
        "\n",
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "\n",
        "X = torch.rand(2, 20)\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we constructed our model by instantiating an **nn.Sequential**, with layers in the order that they should be executed passed as arguments. \n",
        "\n",
        "In short, **nn.Sequential** defines a special kind of Module, the class that presents a block in PyTorch. It maintains an ordered list of constituent Modules.\n",
        "\n",
        "**Note** that each of the two fully-connected layers is an instance of the Linear class which is itself a subclass of Module. \n",
        "\n",
        "The forward propagation (forward) function is also remarkably simple: it chains each block in the list together, passing the output of each as the input to the next. \n",
        "\n",
        "Note that until now, **we have been invoking our models via the construction net(X)** to obtain their outputs. This is actually just shorthand for net. **__call__(X)**."
      ],
      "metadata": {
        "id": "QG02C2XVSNb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  A Custom Block"
      ],
      "metadata": {
        "id": "ydPsgt7sSz82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dibuat kode blok dari awal yang sesuai dengan MLP dengan satu layer tersembunyi dengan 256 unit tersembunyi, dan output layer 10 dimensi. \n",
        "\n",
        "Perhatikan bahwa kelas MLP yang diperlihatkan mewarisi keals yang mewakili sebuah blok. \n",
        "\n",
        "We will heavily rely on the parent class’s functions, supplying only our own constructor (the __init__ function in Python) and the forward propagation function."
      ],
      "metadata": {
        "id": "qsCYtvaeS5sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    # Declare a layer with model parameters. Here, we declare two fully\n",
        "    # connected layers\n",
        "    def __init__(self):\n",
        "        # Call the constructor of the `MLP` parent class `Module` to perform\n",
        "        # the necessary initialization. In this way, other function arguments\n",
        "        # can also be specified during class instantiation, such as the model\n",
        "        # parameters, `params` (to be described later)\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)  # Hidden layer\n",
        "        self.out = nn.Linear(256, 10)  # Output layer\n",
        "\n",
        "    # Define the forward propagation of the model, that is, how to return the\n",
        "    # required model output based on the input `X`\n",
        "    def forward(self, X):\n",
        "        # Note here we use the funtional version of ReLU defined in the\n",
        "        # nn.functional module.\n",
        "        return self.out(F.relu(self.hidden(X)))"
      ],
      "metadata": {
        "id": "eVbq5UpySy_V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mari fokus pada fungsi forward propagation. \n",
        "\n",
        "Perhatikan bahwa fungsi ini mengambil **X** sebagai input, menghitung representasi tersembunyi dengan fungsi aktivasi yang diterapkan, dan mengeluarkan logitnya.\n",
        "\n",
        "Dalam implementasi MLP, kedua layer tersebut merupakan variabel instan. Untuk melihat mengapa hal ini masuk akal, **bayangkan membuat instance dua MLP, net1 dan net2, dan melatihnya pada data yang berbeda**.\n",
        "\n",
        "Secara alami, dapat diharapkan mereka mewakili dua model belajar yang berbeda."
      ],
      "metadata": {
        "id": "-DPeNsaiTiT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertama, fungsi __init__ kami yang disesuaikan memanggil fungsi __init__ kelas induk melalui super().__init__() sehingga kami tidak perlu mengulangi kode boilerplate yang berlaku untuk sebagian besar blok.\n",
        "\n",
        "kemudian buat instance dua lapisan yang terhubung penuh, menugaskannya ke self.hidden dan self.out.\n",
        "\n",
        "ketika diimplementasikan operator baru, kita tidak perlu khawatir tentang fungsi backpropagation atau inisialisasi parameter.\n",
        "\n",
        "Sistem akan menghasilkan fungsi-fungsi ini secara otomatis."
      ],
      "metadata": {
        "id": "1NEERUScUMnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMSgojXRUyGa",
        "outputId": "be0e20bc-f228-4993-ced3-114f3deb8e2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1094, -0.1565,  0.1222, -0.1341, -0.1089,  0.0935,  0.1358,  0.1472,\n",
              "          0.0794,  0.1645],\n",
              "        [-0.1085, -0.1963,  0.0652, -0.2284, -0.1470,  0.0506,  0.1743,  0.1691,\n",
              "          0.0405,  0.0247]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Sequential Block"
      ],
      "metadata": {
        "id": "b7UeupjSU5L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySequential(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for idx, module in enumerate(args):\n",
        "            # Here, `module` is an instance of a `Module` subclass. We save it\n",
        "            # in the member variable `_modules` of the `Module` class, and its\n",
        "            # type is OrderedDict\n",
        "            self._modules[str(idx)] = module\n",
        "\n",
        "    def forward(self, X):\n",
        "        # OrderedDict guarantees that members will be traversed in the order\n",
        "        # they were added\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "Pno4HrcqU40N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf_4O5MMpnpv",
        "outputId": "512bdcab-af94-43f5-ac41-562b559ba469"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1143, -0.0086,  0.0947,  0.2685,  0.1422, -0.1470, -0.0654,  0.0108,\n",
              "          0.0327,  0.1134],\n",
              "        [ 0.1949, -0.0986,  0.1940,  0.2208,  0.2318, -0.1218, -0.0562,  0.2294,\n",
              "          0.0857,  0.2025]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Executing Code in the Forward Propagation Function"
      ],
      "metadata": {
        "id": "FAIE_YZKU7p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Random weight parameters that will not compute gradients and\n",
        "        # therefore keep constant during training\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
        "        self.linear = nn.Linear(20, 20)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.linear(X)\n",
        "        # Use the created constant parameters, as well as the `relu` and `mm`\n",
        "        # functions\n",
        "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
        "        # Reuse the fully-connected layer. This is equivalent to sharing\n",
        "        # parameters with two fully-connected layers\n",
        "        X = self.linear(X)\n",
        "        # Control flow\n",
        "        while X.abs().sum() > 1:\n",
        "            X /= 2\n",
        "        return X.sum()"
      ],
      "metadata": {
        "id": "C0TpdgtjU_OM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxk83KZTpslr",
        "outputId": "eaedc9ee-ebcf-4027-8b5a-1dc10e090d51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0322, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NestMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
        "                                 nn.Linear(64, 32), nn.ReLU())\n",
        "        self.linear = nn.Linear(32, 16)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.linear(self.net(X))\n",
        "\n",
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WTDKdkRpu2E",
        "outputId": "1ec85a0a-aa25-42e7-b092-fbcc676d6a06"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0825, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Efficiency"
      ],
      "metadata": {
        "id": "Le-BOUGpU_f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The avid reader might start to worry about the efficiency of some of these operations. After all, we have lots of dictionary lookups, code execution, and lots of other Pythonic things taking place in what is supposed to be a high-performance deep learning library. The problems of Python’s global interpreter lock are well known. In the context of deep learning, we may worry that our extremely fast GPU(s) might have to wait until a puny CPU runs Python code before it gets another job to run."
      ],
      "metadata": {
        "id": "EAgfEmGcVVPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary"
      ],
      "metadata": {
        "id": "5XhpomRkVET9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Layers are blocks\n",
        "\n",
        "*   Many layers can comprise a block\n",
        "\n",
        "*   Many blocks can comprise a block\n",
        "*   A block can contain code\n",
        "\n",
        "\n",
        "*   Blocks take care of lots of housekeeping, including parameter initialization and backpropagation\n",
        "\n",
        "\n",
        "*   Sequential concatenations of layers and blocks are handled by the Sequential block\n",
        "\n"
      ],
      "metadata": {
        "id": "lJyRff3mVGax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parameter Management**"
      ],
      "metadata": {
        "id": "WlPcQSGfE6cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(size=(2, 4))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNStOIQgFAr_",
        "outputId": "133e2a1a-be0e-41c1-df8f-4b366e1a15d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4906],\n",
              "        [0.4594]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter Access"
      ],
      "metadata": {
        "id": "CrRVSBvkFJOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mari kita mulai dengan cara mengakses parameter dari model yang sudah Anda ketahui. Ketika model didefinisikan melalui Sequential class, kami dapat mengakses layer apa pun dengan mengindeks ke dalam model seolah-olah itu adalah daftar. Parameter setiap lapisan berlokasi di atributnya. Kami dapat memeriksa parameter layer yang sepenuhnya terhubung kedua sebagai berikut."
      ],
      "metadata": {
        "id": "1f6XYYHgFULn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(net[2].state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCD2mEDKFKZu",
        "outputId": "102afe2d-e75f-419e-d867-6d0971f96d1a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[-0.2538,  0.1809,  0.2734, -0.1174,  0.1455, -0.1749, -0.1915,  0.2555]])), ('bias', tensor([0.2022]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The output tells us a few important things**.\n",
        "\n",
        "**Pertama**, lapisan yang sepenuhnya terhubung sepenuhnya ini berisi dua parameter, masing-masing sesuai dengan bobot dan bias layer.\n",
        "\n",
        "**Keduanya** disimpan sebagai pengaparan presisi tunggal (float32). Perhatikan bahwa nama-nama parameter memungkinkan kita untuk secara unik mengidentifikasi parameter setiap lapisan, bahkan dalam jaringan yang berisi ratusan lapisan."
      ],
      "metadata": {
        "id": "GHGUjcHpFez6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Targeted Parameters"
      ],
      "metadata": {
        "id": "zsnygxbYFnZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(net[2].bias))\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w925wRocFsEy",
        "outputId": "a52b593a-4b56-46ae-d47c-abf826f9320f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "Parameter containing:\n",
            "tensor([0.2022], requires_grad=True)\n",
            "tensor([0.2022])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].weight.grad == None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3bcd-NaFtQz",
        "outputId": "a26a125a-522f-4e21-8368-bfd1944c65f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### All Parameters at Once"
      ],
      "metadata": {
        "id": "keMGvpQQFt6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
        "print(*[(name, param.shape) for name, param in net.named_parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKQAth-nFwPz",
        "outputId": "f71bb3e3-8056-4771-bb48-57e4ed78a113"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
            "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()['2.bias'].data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_yap6SjFwrD",
        "outputId": "a0df0185-342b-4f03-f7f2-113ec4e4c849"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2022])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Collecting Parameters from Nested Blocks"
      ],
      "metadata": {
        "id": "oNTePKG5Fyd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def block1():\n",
        "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                         nn.Linear(8, 4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "    net = nn.Sequential()\n",
        "    for i in range(4):\n",
        "        # Nested here\n",
        "        net.add_module(f'block {i}', block1())\n",
        "    return net\n",
        "\n",
        "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
        "rgnet(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY3Xw1J-F0vw",
        "outputId": "51db69fa-5ba5-4232-a6b2-c863ead5a2ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3361],\n",
              "        [-0.3361]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we have designed the network, let us see how it is organized\n",
        "\n",
        "print(rgnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqJ0heWTF8q2",
        "outputId": "fff39b2b-1470-4d86-a7e2-bc3c51b8aafc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena layer-layer itu bersarang hierarkis, kita juga dapat mengaksesnya seolah-olah mengindeks melalui daftar bersarang. Misalnya, kita dapat **mengakses blok utama pertama, di dalamnya sub-blok kedua, dan di dalam bias lapisan pertama,** dengan sebagai berikut."
      ],
      "metadata": {
        "id": "X6UyXtE9GG6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet[0][1][0].bias.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AmyNyMLGOwr",
        "outputId": "0d143d5f-facf-4744-c440-e552b5d3ef2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1920,  0.2569, -0.4182,  0.3486,  0.4197,  0.1028,  0.1998, -0.3811])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter Initialization"
      ],
      "metadata": {
        "id": "xcEgbGPrGRs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Built-in Initialization"
      ],
      "metadata": {
        "id": "JtPa2k7jGTkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mulai dengan memanggil inisialisasi bawaan. Kode di bawah ini menginisialisasi semua parameter berat sebagai variabel acak Gaussian dengan standar deviasi 0,01, sedangkan parameter bias dibersihkan ke nol."
      ],
      "metadata": {
        "id": "HLVjJNmRGWOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_normal(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_normal)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoL26z8lGeD5",
        "outputId": "4876cab0-a9b9-42cc-89e5-0bc59cf1d747"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0020, -0.0031,  0.0051, -0.0069]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also initialize all the parameters to a given constant value (say, 1)\n",
        "\n",
        "def init_constant(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_constant)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0kQCd26Gi-l",
        "outputId": "656c121e-62ae-4d79-e195-509cb68e6327"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1.]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also apply different initializers for certain blocks\n",
        "# Example, initialize the first layer with the Xavier initializer \n",
        "# and initialize the second layer to a constant value of 42\n",
        "\n",
        "def xavier(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "def init_42(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 42)\n",
        "\n",
        "net[0].apply(xavier)\n",
        "net[2].apply(init_42)\n",
        "print(net[0].weight.data[0])\n",
        "print(net[2].weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epApRI2AGmrI",
        "outputId": "17fbffdc-85be-4645-fe56-061a2fea1a0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2255,  0.4151, -0.5354, -0.3998])\n",
            "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom Initialization"
      ],
      "metadata": {
        "id": "76mmPje1Gy-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        print(\"Init\", *[(name, param.shape)\n",
        "                        for name, param in m.named_parameters()][0])\n",
        "        nn.init.uniform_(m.weight, -10, 10)\n",
        "        m.weight.data *= m.weight.data.abs() >= 5\n",
        "\n",
        "net.apply(my_init)\n",
        "net[0].weight[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4D5P2JYG0Wo",
        "outputId": "a02881e3-2fd4-454a-bd8c-fd540ba1f7ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  9.4733, -0.0000, -0.0000],\n",
              "        [ 0.0000, -0.0000, -9.0099, -0.0000]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data[:] += 1\n",
        "net[0].weight.data[0, 0] = 42\n",
        "net[0].weight.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_78XGw0G1mz",
        "outputId": "d30f13d6-b7a3-442e-e520-acf8d9789b1c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([42.0000, 10.4733,  1.0000,  1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tied Parameters"
      ],
      "metadata": {
        "id": "0kfuNKoeG4O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seringkali, ada keinginan untuk membagi parameter di beberapa layer. Mari kita lihat bagaimana melakukannya. Dalam hal berikut ini, dapat dialokasikan layer padat dan kemudian menggunakan parameternya secara khusus untuk mengatur layer lain."
      ],
      "metadata": {
        "id": "I_N5kfxiG__Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to give the shared layer a name so that we can refer to its\n",
        "# parameters\n",
        "shared = nn.Linear(8, 8)\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    nn.Linear(8, 1))\n",
        "net(X)\n",
        "# Check whether the parameters are the same\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "net[2].weight.data[0, 0] = 100\n",
        "# Make sure that they are actually the same object rather than just having the\n",
        "# same value\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzlEXTzrHQ2l",
        "outputId": "6c4b864e-7ce9-47c0-ee5a-06b72ea6d9b7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n",
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contoh ini menunjukkan bahwa parameter dari lapisan kedua dan ketiga diikat. Mereka tidak hanya sama, mereka diwakili oleh tensor persis sama. Dengan demikian, jika kita mengubah salah satu parameter, yang lain juga berubah.\n",
        "\n",
        "**Ketika parameter diikat apa yang terjadi pada gradien?** Karena parameter model berisi gradien, gradien lapisan tersembunyi kedua dan lapisan tersembunyi ketiga ditambahkan bersama selama backpropagation."
      ],
      "metadata": {
        "id": "-U6wyhwxHU7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "\n",
        "\n",
        "*   Terdapat beberapa cara untuk mengakses, menginisialisasi, dan mengikat parameter model.\n",
        "*   Dapat digunakan inisialisasi khusus.\n",
        "\n"
      ],
      "metadata": {
        "id": "UxnIq3IyHjVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom Layers**"
      ],
      "metadata": {
        "id": "EG4motIVH_SI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers without Parameters"
      ],
      "metadata": {
        "id": "iMO9OpTAICtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kelas **centeredlayer** berikut hanya mengurangi rata-rata dari inputnya. Untuk membangunnya, kita hanya perlu mewarisi dari kelas layer dasar dan mengimplementasikan fungsi propagasi maju."
      ],
      "metadata": {
        "id": "-FKaRcQOIOJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class CenteredLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X - X.mean()"
      ],
      "metadata": {
        "id": "dBITy5gEIp23"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lanjut lakukan verifikasi bahwa layer kita berfungsi sebagaimana mestinya dengan memberikan beberapa data. "
      ],
      "metadata": {
        "id": "-z3k9CB9IxLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = CenteredLayer()\n",
        "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTqD4wk3I9Kz",
        "outputId": "82149175-3f7c-4b9a-8ccc-0bdb5e35ce04"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya layer yang kita punya dapat digabungkan sebagai komponen dalam membangun model yang lebih kompleks."
      ],
      "metadata": {
        "id": "KJSFahu-JDDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
      ],
      "metadata": {
        "id": "uj8i51q3JJx9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebagai extra sanity check, kita dapat mengirim data acak melalui jaringan dan memeriksa bahwa meannya sebenarnya 0. Karena kita berurusan dengan angka floating point, maka mungkin masih terlihat nomor nol yang sangat kecil karena kuantisasi."
      ],
      "metadata": {
        "id": "6OsFM-jzJPdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = net(torch.rand(4, 8))\n",
        "Y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7alvjhZnJgeQ",
        "outputId": "5746f2a3-b402-4009-e4e4-1048b08a9c8b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.5193e-09, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Layers with Parameters"
      ],
      "metadata": {
        "id": "j9pD_dzOJiP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "        self.bias = nn.Parameter(torch.randn(units,))\n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "        return F.relu(linear)"
      ],
      "metadata": {
        "id": "sDX26Pq8Jjfb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the MyLinear class and access its model parameters\n",
        "\n",
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_EiZJqLJnKp",
        "outputId": "6da90201-f405-4482-ed87-fb41f8b3b070"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4333, -1.2494, -0.0115],\n",
              "        [ 0.0463, -0.9087,  1.1708],\n",
              "        [ 0.6208,  0.9364, -0.3058],\n",
              "        [ 2.1786, -0.1056, -0.5779],\n",
              "        [ 0.2674,  1.0904, -0.9082]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dapat langsung dilakukan perhitungan propagasi maju menggunakan layer kustom\n",
        "\n",
        "linear(torch.rand(2, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYatYEv5JtEQ",
        "outputId": "31633651-3d70-4c94-a002-88d262c0daa3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5899, 0.0000, 0.5734],\n",
              "        [1.4048, 0.0000, 0.3053]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setelah itu, dapat digunakan sama seperti built-in fully-connected layer\n",
        "\n",
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZwRLYiCJ2it",
        "outputId": "0fe27cb4-5aad-434b-f381-ba6b8452f47b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.1907],\n",
              "        [0.9803]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "\n",
        "\n",
        "*   Kita dapat merancang layer kustom melalui kelas layer dasar. Hal ini memungkinkan kita untuk mendefinisikan layer baru yang fleksibel yang berperilaku berbeda dari layer yang ada di library.\n",
        "\n",
        "*   Setelah didefinisikan, layet khusus dapat dipanggil dalam konteks dan arsitektur sesukanya.\n",
        "*   layer dapat memiliki parameter lokal, yang dapat dibuat melalui fungsi bawaan.\n",
        "\n"
      ],
      "metadata": {
        "id": "B7IozyL2KNbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **File I/O**"
      ],
      "metadata": {
        "id": "cuT3eae4K8xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and Saving Tensors"
      ],
      "metadata": {
        "id": "PdqU6jcPK-0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ],
      "metadata": {
        "id": "sJ2ZweQxLEww"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data\n",
        "\n",
        "x2 = torch.load('x-file')\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcYIT2G_LHHP",
        "outputId": "d7c23338-f2db-4cb3-8ac5-7e15c1f65257"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simpan daftar tensor sehingga dapat membacanya kembali ke memori.\n",
        "\n",
        "y = torch.zeros(4)\n",
        "torch.save([x, y],'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bILlkJ4rLPUe",
        "outputId": "9d987f18-b62e-4169-97aa-e18cad0fde41"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita bahkan dapat menulis dan membaca kamus yang memetakan dari string ke tensor. Hal ini berfungsi ketika kami **ingin membaca atau menulis semua bobot dalam model**."
      ],
      "metadata": {
        "id": "iDY0D_CiLqo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k39_AOsjLZWr",
        "outputId": "d9244fbd-e275-431b-c4fc-991ab7a2f664"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and Saving Model Parameters"
      ],
      "metadata": {
        "id": "XkoN4EMBLxkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output(F.relu(self.hidden(x)))\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ],
      "metadata": {
        "id": "2dFMg-rOLzjf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selanjutnya, disiapkan parameter model sebagai file dengan nama \"mlp.params\"\n",
        "\n",
        "torch.save(net.state_dict(), 'mlp.params')"
      ],
      "metadata": {
        "id": "9bnVr8_5L309"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk memulihkan model, dilakukan instantiate klon dari model MLP asli. Parameter yang disimpan dalam dile secara langusng dibaca."
      ],
      "metadata": {
        "id": "NvyLlLdHMGWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaoeBbbIMYNv",
        "outputId": "0277b7fb-3166-4863-f3c9-ac22cab9999c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena kedua instance memiliki parameter model yang sama, hasil komputasi dari input yang sama x harus sama."
      ],
      "metadata": {
        "id": "lCc7dqC9McQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifikasi\n",
        "\n",
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxSNosMUMcyH",
        "outputId": "d942903a-f8f4-4416-ba05-366ff465ac49"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "\n",
        "\n",
        "*  Fungsi Save and Load dapat digunakan untuk melakukan file I / O untuk objek tensor.\n",
        "\n",
        "*   Seluruh set parameter untuk jaringan dapat disimpan dan dimuat dalam kamus parameter\n",
        "\n",
        "*   Menyimpan arsitektur harus dilakukan dalam kode daripada dalam parameter.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aDsG0-QIMgCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GPUs**"
      ],
      "metadata": {
        "id": "3MlwmNjYM5uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWeY2YJaNAA4",
        "outputId": "362cb935-2700-4f4c-89a8-d0d4714bfc29"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing Devices"
      ],
      "metadata": {
        "id": "UtGSRTeTNH0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, the CPU and GPU can be indicated by torch.device('cpu') and torch.device('cuda'). It should be noted that the cpu device means all physical CPUs and memory. This means that PyTorch’s calculations will try to use all CPU cores. However, a gpu device only represents one card and the corresponding memory. If there are multiple GPUs, we use torch.device(f'cuda:{i}') to represent the ***i^th*** GPU ( ***i*** starts from ***0***). Also, gpu:0 and gpu are equivalent."
      ],
      "metadata": {
        "id": "LZV7fxqHNOmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H7TN32bNIrp",
        "outputId": "21b8fab7-0ff6-43cb-9865-0b7da6006d24"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah GPU yang tersedia\n",
        "\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8VSm4EWNh4p",
        "outputId": "adeb58f8-ca6a-447d-f990-9b5f4f7132dc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tetapkan dua fungsi yang nyaman yang memungkinkan untuk menjalankan kode ketika GPU yang diminta tidak ada."
      ],
      "metadata": {
        "id": "r_xkingSNtmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):  #save\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():  #save\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "try_gpu(), try_gpu(10), try_all_gpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LASxH_xN09A",
        "outputId": "cb50bd19-219a-4301-890a-659ba98c062d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cpu'), [device(type='cpu')])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors and GPUs"
      ],
      "metadata": {
        "id": "3YfoP-KeN4u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor dibuat di CPU\n",
        "# Kita bisa tau tensor berada diperangkat yang mana\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fBSqOiQN-u9",
        "outputId": "1492938f-8d23-4720-f0c5-1469d6986b29"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Storage on the GPU"
      ],
      "metadata": {
        "id": "Z4KqWAwCORdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones(2, 3, device=try_gpu())\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAXepIpJOVWF",
        "outputId": "1793afe5-3666-4352-c643-ec568bdb875d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = torch.rand(2, 3, device=try_gpu(1))\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz8t601fOV32",
        "outputId": "e6eb5131-d3c0-44ce-c627-2a9a5dd9db5d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2008, 0.7702, 0.4452],\n",
              "        [0.3701, 0.2124, 0.4666]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Copying\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "3rckNEwmOeDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "hUZBVsUJSymy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = X.cuda(1)\n",
        "print(X)\n",
        "print(Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "uEoQJWCFOif_",
        "outputId": "3bfdc114-4e18-4df4-e997-6c8e97824bac"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-045efdabb693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y + Z"
      ],
      "metadata": {
        "id": "-9f98uW3Okkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z.cuda(1) is Z"
      ],
      "metadata": {
        "id": "a-itlwrnOljW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks and GPUs"
      ],
      "metadata": {
        "id": "rMH-slDiQRfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential()\n",
        "net.add(nn.Dense(1))\n",
        "net.initialize(ctx=try_gpu())"
      ],
      "metadata": {
        "id": "py_QFmioQT9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net(X)"
      ],
      "metadata": {
        "id": "A6bW2YdBQU9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data().ctx"
      ],
      "metadata": {
        "id": "-fD399cHQV6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "\n",
        "\n",
        "*   Kita dapat menentukan pernyimpanan dan perhitungan, seperti GPU atau CPU. Secara default, data dibuat dalam memori utama dan kemudian gunakan CPU untuk perhitungan.\n",
        "\n",
        "*   Kerangka kerja yang mendalam membutuhkan semua input data untuk perhitungan berada pada perangkat yang sama, baik itu CPU atau GPU yang sama.\n",
        "*   Kesalahan: menghitung kerugian untuk setiap minibatch pada GPU dan melaporkannya kembali ke pengguna pada baris perintah (atau mencatatnya dalam numpy ndarray) akan memicu kunci interpreter global yang menghalangi semua GPU. Lebih baik mengalokasikan memori untuk masuk ke dalam GPU dan hanya memindahkan log yang lebih besar.\n",
        "\n",
        "\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "gmaR4WgVQYMM"
      }
    }
  ]
}